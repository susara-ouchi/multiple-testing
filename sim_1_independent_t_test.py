# -*- coding: utf-8 -*-
"""Sim 1 - Independent t-test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOoZohdGTVTH6DPAtC5ANKdUX37q7Hvh

#Multiple Hypothesis Testing Simulations
###Independent t-tests with H0 ~ N(0,1) and H1~N(k,1)

##Importing libraries
"""

import numpy as np
import statsmodels.api as sm
from statsmodels.stats.multitest import multipletests
import matplotlib.pyplot as plt

"""##Setting up simulations"""

# Set random seed for reproducibility
np.random.seed(42)

# Number of simulations
num_simulations = 10000

# Number of tests (comparisons)
num_tests = 10000  #Fix to a vlaue found in literature

# True effect size (common for all tests)
true_effect_size = 0.55

# Simulate data and conduct t-tests
p_values = []

for _ in range(num_simulations):
    # Simulate data with true effect size
    control_group = np.random.normal(0, 1, size=100)
    treatment_group = np.random.normal(true_effect_size, 1, size=100)

    # Conduct t-test
    p_value = sm.stats.ttest_ind(control_group, treatment_group)[1]
    p_values.append(p_value)

p_values[:10]

threshold = 0.05
significant_p =  [p for p in p_values if p < threshold]
sig_p= len(significant_p)

print("Num. of significant p-values = ",sig_p)

"""##FWER Correction Methods

###1. Bonferroni Correction
"""

# Bonferroni correction
alpha = 0.05
reject_null, corrected_p_values, _, _ = multipletests(p_values, alpha=alpha, method='bonferroni')

bonf_p = corrected_p_values
threshold_bon = threshold/num_tests

significant_p =  [p for p in bonf_p if p < threshold_bon]
sig_p= len(significant_p)

print("Num. of significant p-values = ",sig_p)

# Calculate the proportion of rejected null hypotheses
proportion_rejected = np.mean(reject_null)

# Plot the results
plt.hist(p_values, bins=30, alpha=0.5, label='Uncorrected p-values')
plt.axvline(x=threshold_bon, color='r', linestyle='--', label='Significance level')
plt.title('Distribution of Uncorrected p-values')
plt.xlabel('p-value')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Print results
print(f"Proportion of rejected null hypotheses (uncorrected): {proportion_rejected:.3f}")
print(f"Corrected significance level (Bonferroni-corrected): {alpha / num_tests:.3f}")

"""###2. Sidak Method"""

# Sidak correction
alpha = 0.05
reject_null, corrected_p_values, _, _ = multipletests(p_values, alpha=alpha, method='sidak')

sidak_p = corrected_p_values
threshold_sidak = 1 - (1 - alpha) ** (1 / num_tests)

significant_p =  [p for p in sidak_p if p < threshold_sidak]
sig_p= len(significant_p)

print("Num. of significant p-values = ",sig_p)

# Calculate the proportion of rejected null hypotheses
proportion_rejected = np.mean(reject_null)

# Plot the results
plt.hist(p_values, bins=30, alpha=0.5, label='Uncorrected p-values')
plt.axvline(x=threshold_sidak, color='r', linestyle='--', label='Significance level')
plt.title('Distribution of Uncorrected p-values')
plt.xlabel('p-value')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Print results
print(f"Proportion of rejected null hypotheses (uncorrected): {proportion_rejected:.3f}")
print(f"Corrected significance level (Sidak-corrected): {1 - (1 - alpha) ** (1 / num_tests):.3f}")

"""###Holm-Bonferroni Method"""

# Holm-Bonferroni correction
alpha = 0.05
reject_null, corrected_p_values, _, _ = multipletests(p_values, alpha=alpha, method='holm')

holm_p = corrected_p_values
threshold_holm = alpha

significant_p =  [p for p in holm_p if p < threshold_holm]
sig_p= len(significant_p)

print("Num. of significant p-values = ",sig_p)

# Calculate the proportion of rejected null hypotheses
proportion_rejected = np.mean(reject_null)

# Plot the results
plt.hist(p_values, bins=30, alpha=0.5, label='Uncorrected p-values')
plt.axvline(x=alpha, color='r', linestyle='--', label='Significance level')
plt.title('Distribution of Uncorrected p-values')
plt.xlabel('p-value')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Print results
print(f"Proportion of rejected null hypotheses (uncorrected): {proportion_rejected:.3f}")
print(f"Corrected significance level (Holm-Bonferroni-corrected): {alpha:.3f}")

"""##FDR correction methods

### 1. Benjamini- Hochberg Method
"""

# Benjamini-Hochberg correction
alpha = 0.05
reject_null, corrected_p_values, _, _ = multipletests(p_values, alpha=alpha, method='fdr_bh')

bh_p = corrected_p_values
threshold_bh = alpha

significant_p =  [p for p in bh_p if p < threshold_bh]
sig_p= len(significant_p)

print("Num. of significant p-values = ",sig_p)

# Calculate the proportion of rejected null hypotheses
proportion_rejected = np.mean(reject_null)

# Plot the results
plt.hist(p_values, bins=30, alpha=0.5, label='Uncorrected p-values')
plt.axvline(x=alpha, color='r', linestyle='--', label='Significance level')
plt.title('Distribution of Uncorrected p-values')
plt.xlabel('p-value')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Print results
print(f"Proportion of rejected null hypotheses (uncorrected): {proportion_rejected:.3f}")
print(f"Corrected significance level (Benjamini-Hochberg FDR-corrected): {alpha:.3f}")

"""###2. Storey's Q value"""

from statsmodels.stats.multitest import fdrcorrection

# Storey's q-value correction
alpha = 0.05
reject_null, q_values= fdrcorrection(p_values, alpha=alpha)

storey_q = q_values
threshold_q = alpha

significant_p =  [p for p in storey_q if p < threshold_q]
sig_p= len(significant_p)

print("Num. of significant p-values = ",sig_p)




# Calculate the proportion of rejected null hypotheses
proportion_rejected = np.mean(reject_null)

# Plot the results
plt.hist(p_values, bins=30, alpha=0.5, label='Uncorrected p-values')
plt.axvline(x=alpha, color='r', linestyle='--', label='Significance level')
plt.title('Distribution of Uncorrected p-values')
plt.xlabel('p-value')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Print results
print(f"Proportion of rejected null hypotheses (uncorrected): {proportion_rejected:.3f}")
print("Q-values (Storey's method):")
print(q_values)